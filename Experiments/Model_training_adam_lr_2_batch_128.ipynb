{"cells":[{"cell_type":"code","execution_count":1,"id":"42a236e7-d372-4dba-b263-2b9232004c34","metadata":{"id":"42a236e7-d372-4dba-b263-2b9232004c34","executionInfo":{"status":"ok","timestamp":1681523754791,"user_tz":240,"elapsed":1516,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}},"outputId":"26cd922d-cccf-47eb-ff29-f1d547e20afa","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: torch in ./.local/lib/python3.8/site-packages (1.12.1+cu113)\n","Requirement already satisfied: torchvision in ./.local/lib/python3.8/site-packages (0.13.1+cu113)\n","Requirement already satisfied: typing-extensions in ./.local/lib/python3.8/site-packages (from torch) (4.5.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.local/lib/python3.8/site-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: numpy in ./.local/lib/python3.8/site-packages (from torchvision) (1.21.6)\n","Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchvision) (2.22.0)\n"]}],"source":["!pip3 install torch torchvision"]},{"cell_type":"code","execution_count":2,"id":"24b13a2b-3c99-4f19-8c7f-867bdaa14517","metadata":{"id":"24b13a2b-3c99-4f19-8c7f-867bdaa14517","executionInfo":{"status":"ok","timestamp":1681523756306,"user_tz":240,"elapsed":1510,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}},"outputId":"1c233f3c-bf70-4c14-8901-b2a1589d3271","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: torch-summary in ./.local/lib/python3.8/site-packages (1.4.5)\n"]}],"source":["!pip3 install torch-summary"]},{"cell_type":"code","execution_count":3,"id":"3259d544-50b2-43bc-8aa4-e00adde97302","metadata":{"id":"3259d544-50b2-43bc-8aa4-e00adde97302","executionInfo":{"status":"ok","timestamp":1681523757592,"user_tz":240,"elapsed":1281,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"58e15c9a-2075-4346-8b29-91a7ce6eb949"},"outputs":[{"output_type":"stream","name":"stderr","text":["/home/cc/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","torch.cuda.empty_cache()\n","import math\n","import torchvision\n","import torchvision.transforms as transforms\n","import random\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","from torchvision.utils import make_grid\n","from torch.utils.data import DataLoader,random_split\n","import torch.nn.functional as F\n","from collections import OrderedDict\n","import csv\n","import pandas as pd\n","import numpy as np\n","from torchsummary import summary\n","import torch.optim as optim\n","import os\n","from collections import defaultdict\n","from torch.optim.optimizer import Optimizer\n"]},{"cell_type":"code","execution_count":4,"id":"f0d59fbd-5a92-4c14-b072-58234e3dda35","metadata":{"id":"f0d59fbd-5a92-4c14-b072-58234e3dda35","executionInfo":{"status":"ok","timestamp":1681523757618,"user_tz":240,"elapsed":18,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}}},"outputs":[],"source":["class Cutout(object):\n","    \"\"\"Randomly mask out one or more patches from an image.\n","\n","    Args:\n","        n_holes (int): Number of patches to cut out of each image.\n","        length (int): The length (in pixels) of each square patch.\n","    \"\"\"\n","    def __init__(self, n_holes, length):\n","        self.n_holes = n_holes\n","        self.length = length\n","\n","    def __call__(self, img):\n","        \"\"\"\n","        Args:\n","            img (Tensor): Tensor image of size (C, H, W).\n","        Returns:\n","            Tensor: Image with n_holes of dimension length x length cut out of it.\n","        \"\"\"\n","        h = img.size(1)\n","        w = img.size(2)\n","\n","        mask = np.ones((h, w), np.float32)\n","\n","        for n in range(self.n_holes):\n","            y = np.random.randint(h)\n","            x = np.random.randint(w)\n","\n","            y1 = np.clip(y - self.length // 2, 0, h)\n","            y2 = np.clip(y + self.length // 2, 0, h)\n","            x1 = np.clip(x - self.length // 2, 0, w)\n","            x2 = np.clip(x + self.length // 2, 0, w)\n","\n","            mask[y1: y2, x1: x2] = 0.\n","\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img = img * mask\n","\n","        return img"]},{"cell_type":"code","execution_count":5,"id":"c0ca7944-16af-4999-b9db-e79bbc70fe5b","metadata":{"id":"c0ca7944-16af-4999-b9db-e79bbc70fe5b","executionInfo":{"status":"ok","timestamp":1681523757623,"user_tz":240,"elapsed":2,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}}},"outputs":[],"source":["class Lookahead(Optimizer):\n","    r\"\"\"PyTorch implementation of the lookahead wrapper.\n","\n","    Lookahead Optimizer: https://arxiv.org/abs/1907.08610\n","    \"\"\"\n","\n","    def __init__(self, optimizer, la_steps=5, la_alpha=0.8, pullback_momentum=\"none\"):\n","        \"\"\"optimizer: inner optimizer\n","        la_steps (int): number of lookahead steps\n","        la_alpha (float): linear interpolation factor. 1.0 recovers the inner optimizer.\n","        pullback_momentum (str): change to inner optimizer momentum on interpolation update\n","        \"\"\"\n","        self.optimizer = optimizer\n","        self._la_step = 0  # counter for inner optimizer\n","        self.la_alpha = la_alpha\n","        self._total_la_steps = la_steps\n","        pullback_momentum = pullback_momentum.lower()\n","        assert pullback_momentum in [\"reset\", \"pullback\", \"none\"]\n","        self.pullback_momentum = pullback_momentum\n","\n","        self.state = defaultdict(dict)\n","\n","        # Cache the current optimizer parameters\n","        for group in optimizer.param_groups:\n","            for p in group['params']:\n","                param_state = self.state[p]\n","                param_state['cached_params'] = torch.zeros_like(p.data)\n","                param_state['cached_params'].copy_(p.data)\n","                if self.pullback_momentum == \"pullback\":\n","                    param_state['cached_mom'] = torch.zeros_like(p.data)\n","\n","    def __getstate__(self):\n","        return {\n","            'state': self.state,\n","            'optimizer': self.optimizer,\n","            'la_alpha': self.la_alpha,\n","            '_la_step': self._la_step,\n","            '_total_la_steps': self._total_la_steps,\n","            'pullback_momentum': self.pullback_momentum\n","        }\n","\n","    def zero_grad(self):\n","        self.optimizer.zero_grad()\n","\n","    def get_la_step(self):\n","        return self._la_step\n","\n","    def state_dict(self):\n","        return self.optimizer.state_dict()\n","\n","    def load_state_dict(self, state_dict):\n","        self.optimizer.load_state_dict(state_dict)\n","\n","    def _backup_and_load_cache(self):\n","        \"\"\"Useful for performing evaluation on the slow weights (which typically generalize better)\n","        \"\"\"\n","        for group in self.optimizer.param_groups:\n","            for p in group['params']:\n","                param_state = self.state[p]\n","                param_state['backup_params'] = torch.zeros_like(p.data)\n","                param_state['backup_params'].copy_(p.data)\n","                p.data.copy_(param_state['cached_params'])\n","\n","    def _clear_and_load_backup(self):\n","        for group in self.optimizer.param_groups:\n","            for p in group['params']:\n","                param_state = self.state[p]\n","                p.data.copy_(param_state['backup_params'])\n","                del param_state['backup_params']\n","\n","    @property\n","    def param_groups(self):\n","        return self.optimizer.param_groups\n","\n","    def step(self, closure=None):\n","        \"\"\"Performs a single Lookahead optimization step.\n","        Arguments:\n","            closure (callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        loss = self.optimizer.step(closure)\n","        self._la_step += 1\n","\n","        if self._la_step >= self._total_la_steps:\n","            self._la_step = 0\n","            # Lookahead and cache the current optimizer parameters\n","            for group in self.optimizer.param_groups:\n","                for p in group['params']:\n","                    param_state = self.state[p]\n","                    p.data.mul_(self.la_alpha).add_(param_state['cached_params'], alpha=1.0 - self.la_alpha)  # crucial line\n","                    param_state['cached_params'].copy_(p.data)\n","                    if self.pullback_momentum == \"pullback\":\n","                        internal_momentum = self.optimizer.state[p][\"momentum_buffer\"]\n","                        self.optimizer.state[p][\"momentum_buffer\"] = internal_momentum.mul_(self.la_alpha).add_(\n","                            1.0 - self.la_alpha, param_state[\"cached_mom\"])\n","                        param_state[\"cached_mom\"] = self.optimizer.state[p][\"momentum_buffer\"]\n","                    elif self.pullback_momentum == \"reset\":\n","                        self.optimizer.state[p][\"momentum_buffer\"] = torch.zeros_like(p.data)\n","\n","        return loss"]},{"cell_type":"code","execution_count":6,"id":"2d55c5d8-12c2-4d2e-b076-c10fea214e18","metadata":{"id":"2d55c5d8-12c2-4d2e-b076-c10fea214e18","executionInfo":{"status":"ok","timestamp":1681523757635,"user_tz":240,"elapsed":2,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}}},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","best_acc = 0  \n","start_epoch = 0"]},{"cell_type":"code","execution_count":7,"id":"76d23d25-bb6d-4db1-bd8f-130bac57cbce","metadata":{"id":"76d23d25-bb6d-4db1-bd8f-130bac57cbce","executionInfo":{"status":"ok","timestamp":1681523757659,"user_tz":240,"elapsed":17,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"94e4ad40-bce6-481d-8e7b-5dee98c13942"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"]},"metadata":{},"execution_count":7}],"source":["device"]},{"cell_type":"code","source":["class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_channels, out_channels, stride=1, kernel_size=3):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_channels != self.expansion*out_channels:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, self.expansion*out_channels, kernel_size=kernel_size, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*out_channels)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","class ResNet18(nn.Module):\n","    def __init__(self, block, num_blocks=[2,2,2,2], num_classes=10, kernel_size=3, pool_size=4):\n","        super(ResNet18, self).__init__()\n","        self.in_channels = 64\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=kernel_size, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1, kernel_size=kernel_size)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2, kernel_size=kernel_size)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2, kernel_size=kernel_size)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2, kernel_size=kernel_size)\n","        self.avgpool = nn.AvgPool2d(pool_size)\n","        self.fc = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, out_channels, num_blocks, stride, kernel_size):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_channels, out_channels, stride, kernel_size=kernel_size))\n","            self.in_channels = out_channels * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = self.avgpool(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n"],"metadata":{"id":"ULsnxt4xRp_z","executionInfo":{"status":"ok","timestamp":1681523757662,"user_tz":240,"elapsed":2,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}}},"id":"ULsnxt4xRp_z","execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"id":"12f1b4cf-4d79-472e-8408-0f2efe1e5f58","metadata":{"id":"12f1b4cf-4d79-472e-8408-0f2efe1e5f58","executionInfo":{"status":"ok","timestamp":1681523757692,"user_tz":240,"elapsed":29,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f632d0d3-6dea-4757-b221-36f281dc155c"},"outputs":[{"output_type":"stream","name":"stdout","text":["=================================================================\n","Layer (type:depth-idx)                   Param #\n","=================================================================\n","├─Conv2d: 1-1                            192\n","├─BatchNorm2d: 1-2                       128\n","├─Sequential: 1-3                        --\n","|    └─BasicBlock: 2-1                   --\n","|    |    └─Conv2d: 3-1                  36,864\n","|    |    └─BatchNorm2d: 3-2             128\n","|    |    └─Conv2d: 3-3                  36,864\n","|    |    └─BatchNorm2d: 3-4             128\n","|    |    └─Sequential: 3-5              --\n","├─Sequential: 1-4                        --\n","|    └─BasicBlock: 2-2                   --\n","|    |    └─Conv2d: 3-6                  73,728\n","|    |    └─BatchNorm2d: 3-7             256\n","|    |    └─Conv2d: 3-8                  147,456\n","|    |    └─BatchNorm2d: 3-9             256\n","|    |    └─Sequential: 3-10             8,448\n","├─Sequential: 1-5                        --\n","|    └─BasicBlock: 2-3                   --\n","|    |    └─Conv2d: 3-11                 294,912\n","|    |    └─BatchNorm2d: 3-12            512\n","|    |    └─Conv2d: 3-13                 589,824\n","|    |    └─BatchNorm2d: 3-14            512\n","|    |    └─Sequential: 3-15             33,280\n","├─Sequential: 1-6                        --\n","|    └─BasicBlock: 2-4                   --\n","|    |    └─Conv2d: 3-16                 1,179,648\n","|    |    └─BatchNorm2d: 3-17            1,024\n","|    |    └─Conv2d: 3-18                 2,359,296\n","|    |    └─BatchNorm2d: 3-19            1,024\n","|    |    └─Sequential: 3-20             132,096\n","├─AvgPool2d: 1-7                         --\n","├─Linear: 1-8                            5,130\n","=================================================================\n","Total params: 4,901,706\n","Trainable params: 4,901,706\n","Non-trainable params: 0\n","=================================================================\n","=================================================================\n","Layer (type:depth-idx)                   Param #\n","=================================================================\n","├─Conv2d: 1-1                            192\n","├─BatchNorm2d: 1-2                       128\n","├─Sequential: 1-3                        --\n","|    └─BasicBlock: 2-1                   --\n","|    |    └─Conv2d: 3-1                  36,864\n","|    |    └─BatchNorm2d: 3-2             128\n","|    |    └─Conv2d: 3-3                  36,864\n","|    |    └─BatchNorm2d: 3-4             128\n","|    |    └─Sequential: 3-5              --\n","├─Sequential: 1-4                        --\n","|    └─BasicBlock: 2-2                   --\n","|    |    └─Conv2d: 3-6                  73,728\n","|    |    └─BatchNorm2d: 3-7             256\n","|    |    └─Conv2d: 3-8                  147,456\n","|    |    └─BatchNorm2d: 3-9             256\n","|    |    └─Sequential: 3-10             8,448\n","├─Sequential: 1-5                        --\n","|    └─BasicBlock: 2-3                   --\n","|    |    └─Conv2d: 3-11                 294,912\n","|    |    └─BatchNorm2d: 3-12            512\n","|    |    └─Conv2d: 3-13                 589,824\n","|    |    └─BatchNorm2d: 3-14            512\n","|    |    └─Sequential: 3-15             33,280\n","├─Sequential: 1-6                        --\n","|    └─BasicBlock: 2-4                   --\n","|    |    └─Conv2d: 3-16                 1,179,648\n","|    |    └─BatchNorm2d: 3-17            1,024\n","|    |    └─Conv2d: 3-18                 2,359,296\n","|    |    └─BatchNorm2d: 3-19            1,024\n","|    |    └─Sequential: 3-20             132,096\n","├─AvgPool2d: 1-7                         --\n","├─Linear: 1-8                            5,130\n","=================================================================\n","Total params: 4,901,706\n","Trainable params: 4,901,706\n","Non-trainable params: 0\n","=================================================================\n"]}],"source":["# Model Configuration :\n","\n","\n","model = ResNet18(BasicBlock,  num_blocks = [1,1,1,1],kernel_size=1,pool_size=4)\n","\n","print(summary(model))"]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","best_acc = 0  \n","start_epoch = 0"],"metadata":{"id":"Bjl4S0ySr_C8","executionInfo":{"status":"ok","timestamp":1681523757761,"user_tz":240,"elapsed":42,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}}},"id":"Bjl4S0ySr_C8","execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ef0W2ifnorLX","executionInfo":{"status":"ok","timestamp":1681523923716,"user_tz":240,"elapsed":10,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}},"outputId":"ade4e0cc-ade4-4d5a-c5a1-ce56e8f4abc6"},"id":"ef0W2ifnorLX","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","execution_count":14,"id":"b5d2915e-4d45-491a-8c9b-f977d534fb66","metadata":{"id":"b5d2915e-4d45-491a-8c9b-f977d534fb66","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"029f38d3-7d33-4df6-d91f-2f85fe5d1584","executionInfo":{"status":"error","timestamp":1681523944351,"user_tz":240,"elapsed":2037,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["==> Preparing data..\n","Files already downloaded and verified\n","Files already downloaded and verified\n","\n","Epoch: 0\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 130\u001b[0m\n\u001b[1;32m    127\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, start_epoch\u001b[38;5;241m+\u001b[39mepochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 130\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     test(epoch)\n\u001b[1;32m    132\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n","Cell \u001b[0;32mIn[14], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:166\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m ({},)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[1;32m    168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, kwargs)\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[8], line 47\u001b[0m, in \u001b[0;36mResNet18.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 47\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     48\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(out)\n\u001b[1;32m     49\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(out)\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: Unable to find a valid cuDNN algorithm to run convolution"]}],"source":["# Training\n","\n","import time\n","def train(epoch):\n","    start_time = time.time()\n","    print('\\nEpoch: %d' % epoch)\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, targets) in enumerate(trainloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","    end_time = time.time()\n","    acc = 100.*correct/total\n","    loss = 100.*train_loss/total\n","    print('Train Loss: %.3f | Train Acc: %.3f%% (%d/%d) | time: %.3f seconds'\n","                     % (loss, acc, correct, total, end_time-start_time))\n","    model_results[str(epoch)] =  {\"train\" : {\"acc\" : acc,\"loss\" : loss},\"test\" : {}}\n","    \n","def test(epoch):\n","    global best_acc\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    start_time = time.time()\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(testloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","    end_time = time.time()\n","    # Save checkpoint.\n","    acc = 100.*correct/total\n","    loss = 100.*test_loss/total\n","    print('Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)  | time: %.3f seconds'\n","                     % (loss, acc, correct, total,end_time-start_time))\n","    model_results[str(epoch)]['test']  = {\"acc\" : acc,\"loss\" : loss}\n","    if acc > best_acc:\n","        print('Saving..')\n","        state = {\n","            'net': net.state_dict(),\n","            'acc': acc,\n","            'epoch': epoch,\n","        }\n","        if not os.path.isdir('checkpoint_adam'):\n","            os.mkdir('checkpoint_adam')\n","        torch.save(state, './checkpoint_adam/ckpt_256_lr_2_128.pth')\n","        best_acc = acc\n","        \n","#Model Parameters\n","\n","batch_size = 128\n","lr = 1e-2\n","optim_param = {'la_steps':5,\n","               'la_alpha':0.5\n","              }\n","resume = False \n","model_results = {}\n","\n","#Load model\n","        \n","net = model\n","net = net.to(device)\n","if device == 'cuda':\n","    net = torch.nn.DataParallel(net)\n","\n","if resume:\n","    # Load checkpoint.\n","    print('==> Resuming from checkpoint..')\n","    assert os.path.isdir('checkpoint_adam'), 'Error: no checkpoint directory found!'\n","    checkpoint = torch.load('./checkpoint_adam/ckpt_256_lr_2_128.pth')\n","    net.load_state_dict(checkpoint['net'])\n","    best_acc = checkpoint['acc']\n","    start_epoch = checkpoint['epoch']\n","\n","# Data\n","print('==> Preparing data..')\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","    Cutout(n_holes=1, length=8)\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(\n","    root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(\n","    trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(\n","    root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(\n","    testset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","\n","criterion = nn.CrossEntropyLoss()\n","base_optim = optim.Adam(net.parameters(), lr=lr)\n","\n","Q = math.floor(len(trainset)/batch_size)\n","optimizer = Lookahead(base_optim, **optim_param)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Q)\n","\n","epochs = 50\n","\n","for epoch in range(start_epoch, start_epoch+epochs+1):\n","    train(epoch)\n","    test(epoch)\n","    scheduler.step()\n"]},{"cell_type":"code","execution_count":null,"id":"280a2e82-3826-4946-a1ba-e60a0cf20b77","metadata":{"id":"280a2e82-3826-4946-a1ba-e60a0cf20b77","executionInfo":{"status":"aborted","timestamp":1681523764414,"user_tz":240,"elapsed":2,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}}},"outputs":[],"source":["import json\n","with open('result_adam_256_lr_2_128.json', 'w') as fp:\n","    json.dump(model_results, fp)"]},{"cell_type":"code","execution_count":null,"id":"6162c83a-02d5-415d-a59d-f7115f0c6d45","metadata":{"id":"6162c83a-02d5-415d-a59d-f7115f0c6d45","executionInfo":{"status":"aborted","timestamp":1681523764418,"user_tz":240,"elapsed":11167,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}}},"outputs":[],"source":["checkpoint = torch.load('./checkpoint_adam/ckpt_256_lr_2_128.pth')\n","net.load_state_dict(checkpoint['net'])\n","best_acc = checkpoint['acc']"]},{"cell_type":"code","execution_count":null,"id":"1f88609c-f8ea-4985-a444-b73be5abee9c","metadata":{"id":"1f88609c-f8ea-4985-a444-b73be5abee9c","executionInfo":{"status":"aborted","timestamp":1681523764422,"user_tz":240,"elapsed":11169,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}}},"outputs":[],"source":["best_acc"]},{"cell_type":"code","execution_count":null,"id":"ff3aabef-3499-45f1-ab91-574369acb0c0","metadata":{"id":"ff3aabef-3499-45f1-ab91-574369acb0c0","executionInfo":{"status":"aborted","timestamp":1681523764424,"user_tz":240,"elapsed":11168,"user":{"displayName":"Chandra Shekhar Pandey","userId":"14756136711917828162"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"default:Python","language":"python","name":"conda-env-default-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[{"file_id":"1OmGDjQKr30KMkao_c_D9B1MUPoaMx7oa","timestamp":1681523662201},{"file_id":"1pVxaRgN06U5yV5KO2Db_ohTgE4D0MTRr","timestamp":1681516605667},{"file_id":"1RAbNNqT3XSkZ9bkTYsbVp_kDa7-OL7Xe","timestamp":1681509619100},{"file_id":"https://github.com/swarna97/Deep_Learning_Mini_Project/blob/main/Notebooks/Experiments/Model_Training-Adam-256-lr_1.ipynb","timestamp":1681436367427}]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}